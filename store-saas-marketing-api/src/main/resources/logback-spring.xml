<?xml version="1.0" encoding="UTF-8"?>
<!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL -->
<!-- 日志输出规则 根据当前ROOT 级别，日志输出时，级别高于root默认的级别时 会输出 -->
<!-- 以下 每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志 -->
<!-- 属性描述 scan：性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。
	debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 -->
<configuration scan="false" scanPeriod="60 seconds" debug="false">
	<!-- 定义日志文件 输入位置 -->
	<property name="log_dir" value="/data/webroot/store-saas-marketing/logs" />

	<property name="pattern"
			  value="[store-saas-marketing] %X{requestId} %d %-5level [%X{ctxLogId}][%thread] %logger{5}.%M[%L] - %msg%n" />

	<springProperty scope="context" name="elkEnable" source="elk.enable"
					defaultValue="false" />
	<springProperty scope="context" name="elkHost" source="elk.host"
					defaultValue="localhost" />
	<springProperty scope="context" name="elkPort" source="elk.port"
					defaultValue="5672" />
	<springProperty scope="context" name="elkUsername"
					source="elk.username" defaultValue="test" />
	<springProperty scope="context" name="elkPassword"
					source="elk.password" defaultValue="itsme999" />
	<springProperty scope="context" name="elkVirtualHost"
					source="elk.virtualHost" defaultValue="/dev" />
	<springProperty scope="context" name="elkExchange"
					source="elk.exchange" defaultValue="logback-exchange" />
	<springProperty scope="context" name="elkQueue" source="elk.queue"
					defaultValue="logback-queue" />
	<springProperty scope="context" name="elkRoutingKey"
					source="elk.routingKey" defaultValue="" />
	<springProperty scope="context" name="elkIdentifier"
					source="elk.identifier" defaultValue="store-saas-marketing" />
	<springProperty scope="context" name="elkClientProvidedName"
					source="elk.clientProvidedName" defaultValue="UNDEFINED" />
	<springProperty scope="context" name="sentryEnable"
					source="sentry.enable" defaultValue="false" />
	<!-- log文件保留日期 -->
	<springProperty scope="context" name="logMaxHistory" source="log.maxHistory"
					defaultValue="10" />

	<!-- ConsoleAppender 控制台输出日志 -->
	<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
		<!-- 对日志进行格式化 -->
		<encoder>
			<pattern>${pattern}</pattern>
		</encoder>
	</appender>

	<appender name="ERROR"
			  class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 过滤器，只记录WARN级别及以上的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>WARN</level>
		</filter>
		<file>${log_dir}/error.log</file>
		<!-- 每日生成一个新的日志文件，当日志文件超过10个时删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/error.log.%d{yyyy-MM-dd}</fileNamePattern>
			<maxHistory>${logMaxHistory}</maxHistory>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>

	<appender name="INFO"
			  class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 记录level>=info级别的日志 -->
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>INFO</level>
		</filter>
		<!--仅记录info级别的日志
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        -->
		<file>${log_dir}/info.log</file>
		<!-- 每日生成一个新的日志文件，当日志文件超过10个时删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/info.log.%d{yyyy-MM-dd}</fileNamePattern>
			<maxHistory>${logMaxHistory}</maxHistory>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>

	<appender name="ASYNC_INFO" class="ch.qos.logback.classic.AsyncAppender">
		<discardingThreshold>0</discardingThreshold>
		<queueSize>1024</queueSize>
		<includeCallerData>true</includeCallerData>
		<neverBlock>true</neverBlock>
		<appender-ref ref="INFO" />
	</appender>

	<if condition='property("elkEnable").contains("true")'>
		<then>
			<appender name="ELK"
					  class="org.springframework.amqp.rabbit.logback.AmqpAppender">
				<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
					<level>INFO</level>
				</filter>
				<host>${elkHost}</host>
				<port>${elkPort}</port>
				<username>${elkUsername}</username>
				<password>${elkPassword}</password>
				<virtualHost>${elkVirtualHost}</virtualHost>
				<exchangeName>${elkExchange}</exchangeName>
				<exchangeType>topic</exchangeType>
				<routingKeyPattern>${elkRoutingKey}</routingKeyPattern>
				<declareExchange>true</declareExchange>
				<durable>true</durable>
				<applicationId>${elkIdentifier}</applicationId>
				<clientConnectionProperties>clientProvidedName:${elkClientProvidedName}</clientConnectionProperties>
				<contentType>text/json</contentType>
				<layout class="com.tuhu.store.saas.marketing.config.elk.layout.LogstashLayout"></layout>
			</appender>
		</then>
	</if>

	<if condition='property("sentryEnable").contains("true")'>
		<then>
			<appender name="Sentry" class="com.getsentry.raven.logback.SentryAppender">
				<!-- 过滤器，只记录ERROR级别以上的日志 -->
				<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
					<level>ERROR</level>
				</filter>
				<!--<filter class="com.tuhu.finance.utils.common.filter.SentrySwitchFilter"></filter>-->
				<dsn>http://ed6125fb80c14770a61f1f7c100d45bb:dc6963e0c99f4236b14c3373aa5a2e94@172.17.3.57/27
				</dsn>
			</appender>
		</then>
	</if>

	<appender name="DRUID-APPENDER"
			  class="ch.qos.logback.core.rolling.RollingFileAppender">
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>INFO</level>
		</filter>
		<file>${log_dir}/druid-appender.log</file>
		<!--当日志文件超过10个删除更早的文件 -->
		<rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<fileNamePattern>${log_dir}/druid-appender.log.%d{yyyy-MM-dd}
			</fileNamePattern>
			<maxHistory>${logMaxHistory}</maxHistory>
		</rollingPolicy>
		<encoder>
			<pattern>${pattern}</pattern>
			<immediateFlush>true</immediateFlush>
		</encoder>
	</appender>


	<springProfile name="dev,prd,prod,test,uat">
		<logger name="com.tuhu" level="INFO" additivity="false">
			<appender-ref ref="ASYNC_INFO" />
			<appender-ref ref="ERROR" />
			<appender-ref ref="STDOUT"/>
			<if condition='property("elkEnable").contains("true")'>
				<then>
					<appender-ref ref="ELK" />
				</then>
			</if>
			<if condition='property("sentryEnable").contains("true")'>
				<then>
					<appender-ref ref="Sentry" />
				</then>
			</if>
		</logger>

		<logger name="com.alibaba.druid" level="INFO" additivity="false">
			<appender-ref ref="STDOUT" />
			<appender-ref ref="DRUID-APPENDER" />
			<if condition='property("elkEnable").contains("true")'>
				<then>
					<appender-ref ref="ELK" />
				</then>
				<if condition='property("sentryEnable").contains("true")'>
					<then>
						<appender-ref ref="Sentry" />
					</then>
				</if>
			</if>
		</logger>

		<root level="INFO">
			<appender-ref ref="ASYNC_INFO" />
			<appender-ref ref="ERROR" />
			<appender-ref ref="STDOUT"/>
		</root>
	</springProfile>
</configuration>
